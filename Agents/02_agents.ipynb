{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain\n",
    "\n",
    "## Goals\n",
    "\n",
    "Now, let's build up to a simple chain that combines 4 [concepts](https://python.langchain.com/v0.2/docs/concepts/):\n",
    "\n",
    "* Using [chat messages](https://python.langchain.com/v0.2/docs/concepts/#messages) as our graph state\n",
    "* Using [chat models](https://python.langchain.com/v0.2/docs/concepts/#chat-models) in graph nodes\n",
    "* [Binding tools](https://python.langchain.com/v0.2/docs/concepts/#tools) to our chat model\n",
    "* [Executing tool calls](https://python.langchain.com/v0.2/docs/concepts/#functiontool-calling) in graph nodes \n",
    "\n",
    "![Screenshot 2024-08-21 at 9.24.03 AM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbab08dd607b08df5e1101_chain1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Messages\n",
    "\n",
    "Chat models can use [`messages`](https://python.langchain.com/v0.2/docs/concepts/#messages), which capture different roles within a conversation. \n",
    "\n",
    "LangChain supports various message types, including `HumanMessage`, `AIMessage`, `SystemMessage`, and `ToolMessage`. \n",
    "\n",
    "These represent a message from the user, from chat model, for the chat model to instruct behavior, and from a tool call. \n",
    "\n",
    "Let's create a list of messages. \n",
    "\n",
    "Each message can be supplied with a few things:\n",
    "\n",
    "* `content` - content of the message\n",
    "* `name` - optionally, a message author \n",
    "* `response_metadata` - optionally, a dict of metadata (e.g., often populated by model provider for `AIMessages`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [AIMessage(content=\"Hey There I am Good\", name=\"ChatGPT\")]\n",
    "messages.append(HumanMessage(content=\"FIne Fine \", name=\"Naga\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: ChatGPT\n",
      "\n",
      "Hey There I am Good\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Naga\n",
      "\n",
      "FIne Fine \n"
     ]
    }
   ],
   "source": [
    "for i in messages:\n",
    "    i.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Models\n",
    "\n",
    "[Chat models](https://python.langchain.com/v0.2/docs/concepts/#chat-models) can use a sequence of message as input and support message types, as discussed above.\n",
    "\n",
    "There are [many](https://python.langchain.com/v0.2/docs/concepts/#chat-models) to choose from! Let's work with OpenAI. \n",
    "\n",
    "Let's check that your `OPENAI_API_KEY` is set and, if not, you will be asked to enter it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    model=\"gpt-4o-mini\"\n",
    ")\n",
    "# response = llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Glad to hear that! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 25, 'total_tokens': 37, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'stop', 'logprobs': None}, id='run-ab882fd2-f12e-49ea-a5c4-16bf7bc18084-0', usage_metadata={'input_tokens': 25, 'output_tokens': 12, 'total_tokens': 37, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "Tools are useful whenever you want a model to interact with external systems.\n",
    "\n",
    "External systems (e.g., APIs) often require a particular input schema or payload, rather than natural language. \n",
    "\n",
    "When we bind an API, for example, as a tool we given the model awareness of the required input schema.\n",
    "\n",
    "The model will choose to call a tool based upon the natural language input from the user. \n",
    "\n",
    "And, it will return an output that adheres to the tool's schema. \n",
    "\n",
    "[Many LLM providers support tool calling](https://python.langchain.com/v0.1/docs/integrations/chat/) and [tool calling interface](https://blog.langchain.dev/improving-core-tool-interfaces-and-docs-in-langchain/) in LangChain is simple. \n",
    " \n",
    "You can simply pass any Python `function` into `ChatModel.bind_tools(function)`.\n",
    "\n",
    "![Screenshot 2024-08-19 at 7.46.28 PM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbab08dc1c17a7a57f9960_chain2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's showcase a simple example of tool calling!\n",
    " \n",
    "The `multiply` function is our tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a:int, b:int)->int:\n",
    "    \"\"\"Multiply a and b.\n",
    "    \n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm just a program, but I'm here and ready to help you! How can I assist you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 11, 'total_tokens': 32, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'stop', 'logprobs': None}, id='run-3e52a41d-ce6c-4b73-a22b-df85859f50f8-0', usage_metadata={'input_tokens': 11, 'output_tokens': 21, 'total_tokens': 32, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"hey how are you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools([multiply])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we pass an input - e.g., `\"What is 2 multiplied by 3\"` - we see a tool call returned. \n",
    "\n",
    "The tool call has specific arguments that match the input schema of our function along with the name of the function to call.\n",
    "\n",
    "```\n",
    "{'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm just a computer program, so I don't have feelings, but I'm here and ready to assist you! How can I help you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 56, 'total_tokens': 85, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'stop', 'logprobs': None}, id='run-fae6eb41-8fa1-41d7-92db-8419b5505ab6-0', usage_metadata={'input_tokens': 56, 'output_tokens': 29, 'total_tokens': 85, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"hey how are you\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_lfwa0RzUhpZnViliNdYhAHSB', 'function': {'arguments': '{\"a\":2,\"b\":5}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 62, 'total_tokens': 79, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-7bbc402b-3f98-4e2b-87d6-26ff9fcad035-0', tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 5}, 'id': 'call_lfwa0RzUhpZnViliNdYhAHSB', 'type': 'tool_call'}], usage_metadata={'input_tokens': 62, 'output_tokens': 17, 'total_tokens': 79, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"can you mulitply 2 * 5\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using messages as state\n",
    "\n",
    "With these foundations in place, we can now use [`messages`](https://python.langchain.com/v0.2/docs/concepts/#messages) in our graph state.\n",
    "\n",
    "Let's define our state, `MessagesState`, as a `TypedDict` with a single key: `messages`.\n",
    "\n",
    "`messages` is simply a list of messages, as we defined above (e.g., `HumanMessage`, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict, Annotated\n",
    "from langchain_core.messages import AnyMessage\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: list[AnyMessage]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducers\n",
    "\n",
    "Now, we have a minor problem! \n",
    "\n",
    "As we discussed, each node will return a new value for our state key `messages`.\n",
    "\n",
    "But, this new value will [will override](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers) the prior `messages` value.\n",
    " \n",
    "As our graph runs, we want to **append** messages to to our `messages` state key.\n",
    " \n",
    "We can use [reducer functions](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers) address this.\n",
    "\n",
    "Reducers allow us to specify how state updates are performed.\n",
    "\n",
    "If no reducer function is specified, then it is assumed that updates to the key should *override it* as we saw before.\n",
    " \n",
    "But, to append messages, we can use the pre-built `add_messages` reducer.\n",
    "\n",
    "This ensures that any messages are appended to the existing list of messages.\n",
    "\n",
    "We annotate simply need to annotate our `messages` key with the `add_messages` reducer function as metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since having a list of messages in graph state is so common, LangGraph has a pre-built [`MessagesState`](https://langchain-ai.github.io/langgraph/concepts/low_level/#messagesstate)! \n",
    "\n",
    "`MessagesState` is defined: \n",
    "\n",
    "* With a pre-build single `messages` key\n",
    "* This is a list of `AnyMessage` objects \n",
    "* It uses the `add_messages` reducer\n",
    "\n",
    "We'll usually use `MessagesState` because it is less verbose than defining a custom `TypedDict`, as shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "\n",
    "class MessagesState(MessagesState):\n",
    "    # Add any keys needed beyond messages, which is pre-built \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To go a bit deeper, we can see how the `add_messages` reducer works in isolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial state\n",
    "initial_messages = [AIMessage(content=\"Hello! How can I assist you?\", name=\"Model\"),\n",
    "                    HumanMessage(content=\"I'm looking for information on marine biology.\", name=\"Lance\")\n",
    "                   ]\n",
    "\n",
    "# New message to add\n",
    "new_message = AIMessage(content=\"Sure, I can help with that. What specifically are you interested in?\", name=\"Model\")\n",
    "\n",
    "# Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Hello! How can I assist you?', additional_kwargs={}, response_metadata={}, name='Model', id='fc97d09c-bb7a-478f-bc32-6517d16d2a9b'),\n",
       " HumanMessage(content=\"I'm looking for information on marine biology.\", additional_kwargs={}, response_metadata={}, name='Lance', id='513a6425-5c41-47a1-b801-4fc7b8964394'),\n",
       " AIMessage(content='Sure, I can help with that. What specifically are you interested in?', additional_kwargs={}, response_metadata={}, name='Model', id='bc5d2dae-378a-4e92-b0e5-161309b8e4aa')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "add_messages(initial_messages , new_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our graph\n",
    "\n",
    "Now, lets use `MessagesState` with a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Node\n",
    "\n",
    "def tool_calling_with_llm(state:MessagesState):\n",
    "    return {\"messages\": llm_with_tools.invoke(state[\"messages\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build Graph\n",
    "\n",
    "builder = StateGraph(MessagesState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1bd23573d10>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.add_node(\"LLM_WITH_TOOLS\", tool_calling_with_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1bd23573d10>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.add_edge(START, \"LLM_WITH_TOOLS\")\n",
    "builder.add_edge(\"LLM_WITH_TOOLS\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we pass in `Hey I am Robot.`, the LLM responds without any tool calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hey I am Robot.', additional_kwargs={}, response_metadata={}, id='4037a748-663a-42ca-bf58-7e35996018e7'),\n",
       "  AIMessage(content='Hello, Robot! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 57, 'total_tokens': 69, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_818c284075', 'finish_reason': 'stop', 'logprobs': None}, id='run-c92f33f4-b5f7-4204-aa83-c788569a8202-0', usage_metadata={'input_tokens': 57, 'output_tokens': 12, 'total_tokens': 69, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"messages\":\"Hey I am Robot.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='can u tell me about the marvel movies.', additional_kwargs={}, response_metadata={}, id='7e7fba2c-cfc6-43c9-a7d8-d95b231a0b00'),\n",
       "  AIMessage(content=\"Sure! The Marvel Cinematic Universe (MCU) is a media franchise and shared universe centered around a series of superhero films and television series produced by Marvel Studios. The franchise is based on characters that appear in American comic books published by Marvel Comics. Here's a brief overview of the major phases and notable films:\\n\\n### Phase One (2008-2012)\\n1. **Iron Man (2008)** - The film that kicked off the MCU, introducing Tony Stark, who becomes Iron Man.\\n2. **The Incredible Hulk (2008)** - Follows Bruce Banner as he becomes the Hulk.\\n3. **Iron Man 2 (2010)** - Tony Stark deals with his identity as Iron Man and faces new threats.\\n4. **Thor (2011)** - Introduces the Norse god Thor and his banishment to Earth.\\n5. **Captain America: The First Avenger (2011)** - Tells the origin story of Steve Rogers, who becomes Captain America.\\n6. **The Avengers (2012)** - The first major crossover film, bringing together Iron Man, Thor, Hulk, Captain America, Black Widow, and Hawkeye.\\n\\n### Phase Two (2013-2015)\\n1. **Iron Man 3 (2013)** - Tony Stark faces new challenges post-Avengers.\\n2. **Thor: The Dark World (2013)** - Thor battles an ancient enemy.\\n3. **Captain America: The Winter Soldier (2014)** - Steve Rogers uncovers a conspiracy within S.H.I.E.L.D.\\n4. **Guardians of the Galaxy (2014)** - A group of intergalactic misfits band together to save the galaxy.\\n5. **Avengers: Age of Ultron (2015)** - The Avengers face a new threat from Ultron.\\n6. **Ant-Man (2015)** - Scott Lang becomes Ant-Man and learns to control his powers.\\n\\n### Phase Three (2016-2019)\\n1. **Captain America: Civil War (2016)** - The Avengers face internal conflict over government oversight.\\n2. **Doctor Strange (2016)** - Introduces the Sorcerer Supreme, Doctor Strange.\\n3. **Spider-Man: Homecoming (2017)** - Peter Parker navigates life as a high school student and a superhero.\\n4. **Thor: Ragnarok (2017)** - Thor must save Asgard from Hela and prevent Ragnarok.\\n5. **Black Panther (2018)** - T'Challa returns to Wakanda to take the throne.\\n6. **Avengers: Infinity War (2018)** - The Avengers team up to stop Thanos from collecting the Infinity Stones.\\n7. **Ant-Man and The Wasp (2018)** - Explores the quantum realm and its implications.\\n8. **Captain Marvel (2019)** - Follows Carol Danvers' origins and her role in the universe.\\n9. **Avengers: Endgame (2019)** - The epic conclusion to the Infinity Saga.\\n10. **Spider-Man: Far From Home (2019)** - Peter Parker deals with the aftermath of Endgame.\\n\\n### Phase Four (2021-2022)\\n1. **WandaVision (2021)** - A Disney+ series exploring Wanda Maximoff and Vision's lives.\\n2. **The Falcon and the Winter Soldier (2021)** - Follows Sam Wilson and Bucky Barnes post-Endgame.\\n3. **Loki (2021)** - Centers on the variant Loki and the multiverse.\\n4. **Black Widow (2021)** - A prequel focusing on Natasha Romanoff's past.\\n5. **Shang-Chi and the Legend of the Ten Rings (2021)** - Introduces Shang-Chi and his journey.\\n6. **Eternals (2021)** - A new group of heroes from the Celestial race.\\n7. **Spider-Man: No Way Home (2021)** - Explores the multiverse with Spider-Man.\\n8. **Doctor Strange in the Multiverse of Madness (2022)** - Delves deeper into the multiverse.\\n9. **Thor: Love and Thunder (2022)** - Thor's journey continues with new and old friends.\\n\\n### Upcoming Films\\nMarvel continues to expand with new projects announced for Phase Five and beyond, including sequels and new character introductions.\\n\\n### Conclusion\\nThe MCU has become a cultural phenomenon, known for its interconnected storylines, character development, and impressive visual effects. Each film often includes post-credits scenes that tease future projects, keeping fans eagerly anticipating what comes next!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 926, 'prompt_tokens': 61, 'total_tokens': 987, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'stop', 'logprobs': None}, id='run-00da0ea0-68ea-46c1-b7e8-b43adc6e69fa-0', usage_metadata={'input_tokens': 61, 'output_tokens': 926, 'total_tokens': 987, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"messages\":\"can u tell me about the marvel movies.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='can u multiply 5 and 6.', additional_kwargs={}, response_metadata={}, id='d1afa489-d660-48b3-8528-0b9c1e7a2564'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_rdQYnb4O0LsIDPOl9k4Vbphe', 'function': {'arguments': '{\"a\":5,\"b\":6}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 61, 'total_tokens': 78, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-6a53626f-2f6e-44da-b693-ba458a91e75f-0', tool_calls=[{'name': 'multiply', 'args': {'a': 5, 'b': 6}, 'id': 'call_rdQYnb4O0LsIDPOl9k4Vbphe', 'type': 'tool_call'}], usage_metadata={'input_tokens': 61, 'output_tokens': 17, 'total_tokens': 78, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"messages\":\"can u multiply 5 and 6.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
