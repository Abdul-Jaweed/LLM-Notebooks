{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "apiKey:str = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(api_key=apiKey, model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm sorry, but I don't have access to personal information about users unless it has been shared with me in the course of our conversation. If you'd like to share your name or any other information, feel free to do so!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 13, 'total_tokens': 58, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0ba0d124f1', 'finish_reason': 'stop', 'logprobs': None}, id='run-98e0f2f1-7f66-44b9-8c10-7ef6c06c8d89-0', usage_metadata={'input_tokens': 13, 'output_tokens': 45, 'total_tokens': 58, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"can you tell me my name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noInput = PromptTemplate(\n",
    "    input_variables=[\"language\", \"topic\"],\n",
    "    template=\"give me a {language} {topic} code??\"\n",
    ")\n",
    "noInputFormated = noInput.format(language=\"java\", topic=\"dictionary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give me a java dictionary code??\n"
     ]
    }
   ],
   "source": [
    "print(noInputFormated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Certainly! In Python, you can create an array using the built-in `list` data structure or by using the `array` module for more specific array types. Below are examples of both methods.\\n\\n### Using a List\\n\\n```python\\n# Creating a list (array) in Python\\nmy_list = [1, 2, 3, 4, 5]\\n\\n# Accessing elements\\nprint(my_list[0])  # Output: 1\\nprint(my_list[1])  # Output: 2\\n\\n# Adding an element\\nmy_list.append(6)\\n\\n# Removing an element\\nmy_list.remove(3)\\n\\n# Printing the updated list\\nprint(my_list)  # Output: [1, 2, 4, 5, 6]\\n```\\n\\n### Using the `array` Module\\n\\nIf you need a more efficient array for numerical data, you can use the `array` module:\\n\\n```python\\nimport array\\n\\n# Creating an array of integers\\nmy_array = array.array('i', [1, 2, 3, 4, 5])\\n\\n# Accessing elements\\nprint(my_array[0])  # Output: 1\\nprint(my_array[1])  # Output: 2\\n\\n# Adding an element\\nmy_array.append(6)\\n\\n# Removing an element\\nmy_array.remove(3)\\n\\n# Printing the updated array\\nprint(my_array)  # Output: array('i', [1, 2, 4, 5, 6])\\n```\\n\\n### Explanation:\\n- In the first example, we use a list, which is a flexible and commonly used data structure in Python.\\n- In the second example, we use the `array` module, which is more memory efficient for large arrays of numeric data.\\n\\nFeel free to choose the one that best fits your needs!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 376, 'prompt_tokens': 14, 'total_tokens': 390, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f59a81427f', 'finish_reason': 'stop', 'logprobs': None}, id='run-120d3b41-ab7d-42e1-974c-25daa5fcdbc8-0', usage_metadata={'input_tokens': 14, 'output_tokens': 376, 'total_tokens': 390, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "InputData = PromptTemplate.from_template(\"give me a {language} {topic} code??\")\n",
    "InputData = InputData.invoke({\"language\":\"python\", \"topic\":\"array\"})\n",
    "llm.invoke(InputData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='give me a python array code??')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The 2019 Indian general election was held in multiple phases from April to May 2019. The Bharatiya Janata Party (BJP), led by Prime Minister Narendra Modi, won a significant majority in this election, securing 303 out of 543 seats in the Lok Sabha. Modi continued as Prime Minister following this victory. If you have any specific questions about the election or its outcomes, feel free to ask!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 86, 'prompt_tokens': 17, 'total_tokens': 103, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_9b78b61c52', 'finish_reason': 'stop', 'logprobs': None}, id='run-d23c87dc-2011-4340-8a16-34e5324faa77-0', usage_metadata={'input_tokens': 17, 'output_tokens': 86, 'total_tokens': 103, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = llm.invoke(noInputFormated)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who will win the 2020 us Election ??\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(noInput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The 2020 U.S. Presidential Election was held on November 3, 2020, and Joe Biden, the Democratic candidate, won the election against the incumbent president, Donald Trump. Biden officially took office on January 20, 2021. If you have any questions about the election or its aftermath, feel free to ask!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 69, 'prompt_tokens': 17, 'total_tokens': 86, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f59a81427f', 'finish_reason': 'stop', 'logprobs': None}, id='run-0e4957d6-10f7-4d8f-8fe3-8734d587eaf2-0', usage_metadata={'input_tokens': 17, 'output_tokens': 69, 'total_tokens': 86, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatTemplate = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\",\"You're are Director.\"),\n",
    "        (\"user\",\"can you tell me about the avenger movie.\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatTemplate = ChatPromptTemplate(\n",
    "    [\n",
    "        SystemMessage(content=\"You're are Director.\"),\n",
    "        HumanMessage(content=\"can you tell me about the avenger movie.\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=[], input_types={}, partial_variables={}, messages=[SystemMessage(content=\"You're are Director.\", additional_kwargs={}, response_metadata={}), HumanMessage(content='can you tell me about the avenger movie.', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = ChatPromptTemplate([\n",
    "    (\"system\", \"You are a helpful AI bot. Your name is {name}.\"),\n",
    "    (\"human\", \"Hello,how are you doing? I am jaweed and nice to meet you\"),\n",
    "    (\"ai\", \"I'm doing well, thanks!\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "])\n",
    "\n",
    "\n",
    "prompt_value = template.invoke(\n",
    "    {\n",
    "        \"name\": \"Bob\",\n",
    "        \"user_input\": \"What is my name?\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatTemplate = ChatPromptTemplate(\n",
    "    [\n",
    "        SystemMessage(content=\"You are a helpful AI bot. Your name is {name}.\"),\n",
    "        HumanMessage(content=\"Hello,how are you doing? I am venkat and nice to meet you\"),\n",
    "        AIMessage(content=\"I'm doing well, thanks!\"),\n",
    "        HumanMessage(content=\"{user_input}\")\n",
    "    ],\n",
    ")\n",
    "\n",
    "prompt_value = chatTemplate.invoke(\n",
    "    {\n",
    "        \"name\": \"Bob\",\n",
    "        \"user_input\": \"What is my name?\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatTemplate = ChatPromptTemplate(\n",
    "    [\n",
    "        SystemMessage(content=\"You are a helpful AI bot. Your name is {name}.\"),\n",
    "        HumanMessage(content=\"Hello,how are you doing? I am venkat and nice to meet you\"),\n",
    "        AIMessage(content=\"I'm doing well, thanks!\"),\n",
    "        HumanMessage(content=\"{user_input}\")\n",
    "    ],\n",
    "    MessagesPlaceholder(\"chat_history\")\n",
    ")\n",
    "\n",
    "prompt_value = chatTemplate.invoke(\n",
    "    {\"chat_history\", HumanMessage(content={\n",
    "        \"name\": \"Bob\",\n",
    "        \"placehoder\": \"chat_history\"\n",
    "    })}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt_template.invoke({\"msgs\": [HumanMessage(content=\"hi!\")]})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='It seems like you entered a placeholder. How can I assist you today, Venkat?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 58, 'total_tokens': 76, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0ba0d124f1', 'finish_reason': 'stop', 'logprobs': None}, id='run-36f6cf78-83ea-4f8c-b3d3-c50d2fc4a1a0-0', usage_metadata={'input_tokens': 58, 'output_tokens': 18, 'total_tokens': 76, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(prompt_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful AI bot. Your name is Bob.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hello,how are you doing? I am jaweed and nice to meet you', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I'm doing well, thanks!\", additional_kwargs={}, response_metadata={}), HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Jaweed. Nice to meet you!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 58, 'total_tokens': 69, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_9b78b61c52', 'finish_reason': 'stop', 'logprobs': None}, id='run-5436c5fa-4dc8-4d24-beaf-2b02e2cbc00b-0', usage_metadata={'input_tokens': 58, 'output_tokens': 11, 'total_tokens': 69, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(prompt_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=[] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=\"You're are Director.\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='can you tell me about the avenger movie.'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "print(chatTemplate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=\"You're are Director.\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='can you tell me about the avenger movie.'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "print(chatTemplate.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    {\"role\": \"system\", \"content\": \"You're are Director.\"},\n",
    "    {\"role\": \"user\", \"content\": \"can you tell me about the avenger movie.\"}\n",
    "  ],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noInput = PromptTemplate(\n",
    "    input_variables=[\"language\", \"topic\", \"text\"],\n",
    "    template=\"can you translate the {language} words {text} to {to_translate} ??\"\n",
    ")\n",
    "text = \"\"\n",
    "noInputFormated = noInput.format(language=\"english\", to_translate=\"telugu\", text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(noInputFormated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The phrase \"How are you\" can be translated to Telugu as \"నువ్వు ఎలా ఉన్నావు?\" (Nuvvu ēlā unnāvu?) when addressing someone informally, or \"మీరు ఎలా ఉన్నారు?\" (Mīru ēlā unnāru?) when addressing someone formally.'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
